\documentclass[times,numbers=noenddot]{itmo-student-thesis}

%% Опции пакета:
%% - specification - если есть, генерируется задание, иначе не генерируется
%% - annotation - если есть, генерируется аннотация, иначе не генерируется
%% - times - делает все шрифтом Times New Roman, собирается с помощью xelatex
%% - languages={...} - устанавливает перечень используемых языков. По умолчанию это {english,russian}.
%%                     Последний из языков определяет текст основного документа.

%% Делает запятую в формулах более интеллектуальной, например:
%% $1,5x$ будет читаться как полтора икса, а не один запятая пять иксов.
%% Однако если написать $1, 5x$, то все будет как прежде.
\usepackage{icomma}

%% Один из пакетов, позволяющий делать таблицы на всю ширину текста.
\usepackage{tabularx}

%% Данные пакеты необязательны к использованию в бакалаврских/магистерских
%% Они нужны для иллюстративных целей
%% Начало
\usepackage{tikz}
\usetikzlibrary{arrows}
\usepackage{filecontents}
\begin{filecontents}{bachelor-thesis.bib}
@online{ doerr-doerr-lambda-lambda-self-adjustment-arxiv,
    year        = {2015},
    title       = {Optimal Parameter Choices Through Self-Adjustment: Applying the 1/5-th Rule in
                   Discrete Settings},
    author      = {Benjamin Doerr and Carola Doerr},
    url         = {http://arxiv.org/abs/1504.03212},
    year        = {2015},
    langid      = {english}
}

@inproceedings{ example-english,
    year        = {2015},
    booktitle   = {Proceedings of IEEE Congress on Evolutionary Computation},
    author      = {Maxim Buzdalov and Anatoly Shalyto},
    title       = {Hard Test Generation for Augmenting Path Maximum Flow
                   Algorithms using Genetic Algorithms: Revisited},
    pages       = {2121-2128},
    langid      = {english}
}

@article{ example-russian,
    author      = {Максим Викторович Буздалов},
    title       = {Генерация тестов для олимпиадных задач по программированию
                   с использованием генетических алгоритмов},
    journal     = {Научно-технический вестник {СПбГУ} {ИТМО}},
    number      = {2(72)},
    year        = {2011},
    pages       = {72-77},
    langid      = {russian}
}

@article{ unrestricted-jump-evco,
    author      = {Maxim Buzdalov and Benjamin Doerr and Mikhail Kever},
    title       = {The Unrestricted Black-Box Complexity of Jump Functions},
    journal     = {Evolutionary Computation},
    year        = {2016},
    note        = {Accepted for publication},
    langid      = {english}
}

@book{ bellman,
    author      = {R. E. Bellman},
    title       = {Dynamic Programming},
    address     = {Princeton, NJ},
    publisher   = {Princeton University Press},
    numpages    = {342},
    pagetotal   = {342},
    year        = {1957},
    langid      = {english}
}
\end{filecontents}
%% Конец

%% Указываем файл с библиографией.
\addbibresource{bachelor-thesis.bib}

\begin{document}

\studygroup{К34212}
\title{Разработка HTTP-сервера высокой производительности для СУБД Picodata: анализ и первичная реализация}
\author{Тельнов Федор Николаевич}{Тельнов Ф.Н.}
\supervisor{Самохин Никита Юрьевич}{Самохин Н.Ю.}
\curator{Федоров Дмитрий Алексеевич}{Федоров Д.А.}

\publishyear{2025}

%% Задание
%%% Техническое задание и исходные данные к работе
\technicalspec{Требуется разработать стилевой файл для системы \LaTeX, позволяющий оформлять бакалаврские работы и магистерские диссертации
	на кафедре компьютерных технологий Университета ИТМО. Стилевой файл должен генерировать титульную страницу пояснительной записки,
	задание, аннотацию и содержательную часть пояснительной записк. Первые три документа должны максимально близко соответствовать шаблонам документов,
	принятым в настоящий момент на кафедре, в то время как содержательная часть должна максимально близко соответствовать ГОСТ~7.0.11-2011
	на диссертацию.}

%%% Содержание выпускной квалификационной работы (перечень подлежащих разработке вопросов)
\plannedcontents{Пояснительная записка должна демонстрировать использование наиболее типичных конструкций, возникающих при составлении
	пояснительной записки (перечисления, рисунки, таблицы, листинги, псевдокод), при этом должна быть составлена так, что демонстрируется
	корректность работы стилевого файла. В частности, записка должна содержать не менее двух приложений (для демонстрации нумерации рисунков и таблиц
	по приложениям согласно ГОСТ) и не менее десяти элементов нумерованного перечисления первого уровня вложенности (для демонстрации корректности
	используемого при нумерации набора русских букв).}

%%% Исходные материалы и пособия
\plannedsources{\begin{enumerate}
		\item ГОСТ~7.0.11-2011 <<Диссертация и автореферат диссертации>>;
		\item С.М. Львовский. Набор и верстка в системе \LaTeX;
		\item предыдущий комплект стилевых файлов, использовавшийся на кафедре компьютерных технологий.
	\end{enumerate}}

%%% Цель исследования
\researchaim{Разработка удобного стилевого файла \LaTeX
	для бакалавров и магистров кафедры компьютерных технологий.}

%%% Задачи, решаемые в ВКР
\researchtargets{\begin{enumerate}
		\item обеспечение соответствия титульной страницы, задания и аннотации шаблонам, принятым в настоящее время на кафедре;
		\item обеспечение соответствия содержательной части пояснительной записки требованиям ГОСТ~7.0.11-2011 <<Диссертация и автореферат диссертации>>;
		\item обеспечение относительного удобства в использовании~--- указание данных об авторе и научном руководителе один раз и в одном месте, автоматический подсчет числа тех или иных источников.
	\end{enumerate}}

%%% Использование современных пакетов компьютерных программ и технологий
\addadvancedsoftware{Пакет \texttt{tabularx} для чуть более продвинутых таблиц}{\ref{sec:tables}, Приложения~\ref{sec:app:1}, \ref{sec:app:2}}
\addadvancedsoftware{Пакет \texttt{biblatex} и программное средство \texttt{biber}}{Список использованных источников}

%%% Краткая характеристика полученных результатов
\researchsummary{Получился, надо сказать, практически неплохой стилевик. В 2015--2018 годах
	его уже использовали некоторые бакалавры и магистры. Надеюсь на продолжение.}

%%% Гранты, полученные при выполнении работы
\researchfunding{Автор разрабатывал этот стилевик исключительно за свой счет и на
	добровольных началах. Однако значительная его часть была бы невозможна, если бы
	автор не написал в свое время кандидатскую диссертацию в \LaTeX,
	а также не отвечал за формирование кучи научно-технических отчетов по гранту,
	известному как <<5-в-100>>, что происходило при государственной финансовой поддержке
	ведущих университетов Российской Федерации (субсидия 074-U01).}

%%% Наличие публикаций и выступлений на конференциях по теме выпускной работы
\researchpublications{По теме этой работы я (к счастью!) ничего не публиковал.
	\begin{refsection}
		Однако покажу, как можно ссылаться на свои публикации из списка литературы:
		\nocite{example-english, example-russian}
		\printannobibliography
	\end{refsection}
}

%% Эта команда генерирует титульный лист и аннотацию.
\maketitle{Бакалавр}

%% Оглавление
\tableofcontents

\startshortenspage

API – Application Programming Interface

HTTP – HyperText Transfer Protocol

СУБД – Система управления базами данных

I/O - Input / Output

SIMD - Single Instruction Multiple Data

\startterminologypage

HTTP (HyperText Transfer Protocol) - протокол прикладного уровня, который используется для передачи данных в сети Интернет.
Он определяет правила и формат обмена данными между клиентом (например, веб-браузером) и сервером.

Акторные группы - группы пользователей, объединенных общими потребностями, проблемами, интересами и используемыми технологиями.
Отдельные акторные группы чаще всего действуют независимо, даже находясь в рамках одной организации.

SLA (Service Level Agreement) - договор между поставщиком услуг и их потребителем.
В рамках программного обеспечения часто упрощается в форме максимальной задержки при указанном персинтиле.


%% Макрос для введения. Совместим со старым стилевиком.
\startprefacepage

В мире российского IT пользуется популярностью in-memory база данных Tarantool\nameref{lit:tt_doc}.
Ею пользуются как гиганты для реализации критичных к производительности сервисов, так и частные лица, заинтересованные в быстром проектировании отказоустойчивых и эффективных решений.
Долгое время приложения для Tarantool писались на языке Lua, однако в последнее время фокус сообщества начинает смещаться в сторону Rust.
Это объясняется неординарной безопасностью и эффективностью, которую предоставляет этот язык.
Компания Picodata, помимо создания собственного продукта СУБД Picodata\nameref{lit:picodata_doc}, также занимается поддержкой и развитием Rust-экосистемы, фактически являясь единственным крупным ее мейнтейнером.

Lua - достаточно популярный выбор, когда речь заходит об интеграции бизнес-логики пользователя с существующим C API в рамках некоторого высокопроизводительного приложения.
Так, например, в рамках прокси и балансировщика нагрузки HAProxy можно реализовывать собственную логику маршрутизации запросов на языке Lua.
Обычно в рамках среды выполнения и диалекта языка в таком случае используется Lua JIT - версия интерпретатора Lua, разработанная с целью повышения производительности.
В рамках разработки СУБД Tarantool создатели пошли тем же маршрутом, и конечные пользователи получили возможность достаточно просто реализовывать бизнес-логику сложных систем обработки и хранения данных, при этом получая в среднем удовлетворяющий уровень производительности.
Однако, как показывает практика, системы в рамках СУБД Tarantool, написанные на языке Lua, зачастую не удовлетворяют SLA\nameref{lit:highload} - Lua JIT дает временами потрясающую производительность, но имеет тенденцию к деградации.
Переходным периодом в жизни таких проектов можно считать интеграцию библиотек, написанных на других языках - например, для ускорения разбора JSON-запросов можно использовать SIMD-совместимую библиотеку на языке C++, добавив к ней API-обертку на языке Lua.

Компания Picodata решила пойти более кардинальным путем - в рамках собственного форка Tarantool и, в конечном итоге, в рамках СУБД Picodata, было решено постепенно избавить пользователя от языка Lua вовсе, предложив ему альтернативу для написания бизнес-приложений.
Целевым языком, на который был осуществлен переход, стал Rust: были созданы вспомогательные биндинги к C API СУБД Tarantool, утилиты для разработки.
Этот переход уже позволяет создавать высокопроизводительные системы полностью на современном языке программирования Rust - в результате SLA поддерживать стало проще, нет непредвиденных замедлений из-за Lua JIT.
Однако все еще остается проблема - множество частей СУБД Tarantool, которые внутренне используются СУБД Picodata, по-прежнему реализованы на языке Lua.
Например, к подобным компонентам относится реализация виртуального шардирования - библиотека vshard.
Наблюдая проблемы при эксплуатации, связанные с подобными компонентами, компания Picodata ведет инициативы по переписыванию этих частей на Rust.
Дополнительным преимуществом и упрощением в данном случае является постоянно расширяющаяся и активно поддерживаемая экосистема Rust-библиотек.

На данный момент приемом и обработкой входных данных от клиентов в рамках протокола HTTP занимается компонент “tarantool/http”\nameref{lit:tt_http}, представляющий собой HTTP-сервер на языке Lua.
После получения данные в виде набора байт сначала разбираются и трансформируются в Lua-специфичный тип - таблицы.
Затем таблицы последовательно помещаются на стек и поглощаются с помощью биндингов на стороне Rust, переводятся в Rust-специфичные типы с помощью фреймворка “shors”\nameref{lit:shors}, разработанного командой Picodata.
В результате каждый пользовательский запрос проходит этот путь: ценное время тратится на лишнюю трансформацию данных, что приводит к увеличению времени задержки запросов.
Если же старый компонент на Lua переписать на Rust, то данные сразу же будут доступны в нужной среде исполнения и в необходимом для конечного бизнес-приложения пользователя формате, что упрощает поддержку установленного SLA для сетевых приложений.
Кроме того, немаловажное преимущество - возможность использовать данный HTTP-сервер в рамках процесса работы самой СУБД Picodata.
Встроенных HTTP-эндпоинтов не так много, они нужны в основном для административных целей, но влияют на общую производительность кластера в виду однопоточной природы исполнительной(транзакционной) части СУБД Picodata.

Целью данной работы является разработка HTTP-сервера высокой производительности для СУБД Picodata.
Для начала будет проведен детальный анализ существующего решения - комбинации фреймворка “shors” на языке Rust и HTTP-сервера на Lua от Tarantool.
Будут выбраны акторные группы существующего решения, построена диаграмма прецедентов.
К новому продукту будут составлены функциональные и нефункциональные требования.
После будет представлено новое решение - полноценный HTTP-сервер на языке Rust для СУБД Picodata.
Конечное решение будет использоваться в качестве замены существующему в рамках пользовательских бизнес-приложений - в терминологии СУБД Picodata они называются плагинами, а также в рамках работы самого процесса Picodata.

В рамках данной работы были поставлены и достигнуты следующие цели:

\begin{enumerate}[label=\arabic*.]
	\item рассмотреть текущее решение, его преимущества и недостатки;
	\item изучить акторные группы текущего решения, построить диаграмму прецедентов;
	\item сформировать функциональные и нефункциональные требования для нового продукта;
	\item сформировать архитектуру будущего решения;
	\item сформировать первичную реализацию решения.
\end{enumerate}

%% Начало содержательной части.
\leftalignedtrue
\chapter{Исследование}
\leftalignedfalse

\section{Анализ существующего решения}\label{sec:analyze_existing}

Чтобы детально разобрать интеграцию старого HTTP-сервера на Lua со внутренними процессами СУБД Tarantool, необходимо рассмотреть архитектуру СУБД Tarantool по части реализации основного транзакционного потока и I/O.
Транзакционный поток Tarantool построен на принципе user-space потоков, которые по установленной терминологии документации Tarantool зовутся файберами.
Часто их также называют зелеными потоками или корутинами: главное их преимущество в легковесности - нет нужды в дорогостоящих переключениях контекста, в рамках одного системного потока уживаются множество параллельных “зеленых” потоков, выполняющихся по очереди.
Это позволяет оптимально утилизировать доступные ресурсы - так, весь процесс СУБД Tarantool использует всего несколько системных потоков.
У такого подхода есть и недостаток - нет принудительного переключения контекста.
Если при классической модели системных потоков некоторый поток процесса блокируется или неэффективно расходует ресурсы на некоторую долгую операцию, то он все равно будет переключен операционной системой.
Конечно, этот вопрос контролируется планировщиком ОС, но суть неизменна - не преэмптивное планирование позволяет принудительное переключение, что часто позволяет корректное выполнение даже при ошибке логики приложения.
При преэмптивном планировании, характерном в том числе для user-space потоков, такой возможности нет - если в рамках логики приложения по какой-то причине “зеленый” поток блокируется, он заблокирует выполнение остальных участников кооперативной многозадачности в рамках одного системного потока.
Особенно это критично, если используется единый системный поток - его блокировка будет означать остановку выполнения всех остальных частей приложения.
Это как раз случай Tarantool - большая часть пользовательской логики исполняется в одном транзакционном потоке.
Поэтому разработчики приложений на базе Tarantool стараются реализовать алгоритмы в файберах в итеративной манере - каждый файбер при переключении на него занимает немного процессорного времени, и снова засыпает, добровольно возвращая контроль над потоком планировщику.

В традиционной модели системных потоков в, например, синхронном сетевом вызове нет ничего плохого - при ожидании на сокете с использованием необходимого системного вызова, поток будет заблокирован и переключен планировщиком ОС, пока не будут получены данные.
В рамках же модели user-space потоков любой блокирующий вызов приведет к блокировке остальных участников.
Поэтому по части I/O-вызовов для user-space потоков разрабатывается собственная неблокирующая система, внутренне использующая функциональность встроенных I/O системных вызовов ОС.
В Tarantool пошли схожим путем: используется библиотека libev\nameref{lit:libev} на языке C, предоставляющая реализацию event loop с интеграцией неблокирующих вызовов.
На рисунке 1.1 показана упрощенная схема работы транзакционного потока из документации Tarantool, построенного поверх libev - она демонстрирует чередование user-space потоков в рамках libev event loop, их обращение к арене - области памяти узла, отвечающей за непосредственное хранение данных.

\begin{figure}[!h]
	\caption*{Рисунок 1.1 - Схема работы event loop - файберы и арена}\label{fig1}
	\centering
	\includegraphics[scale=0.7]{tt_evloop}
\end{figure}


Указанная реализация предоставляет производительную однопоточную среду исполнения, хорошо подходит для реализации in-memory базы данных, однако требует аккуратного подхода к реализации любого I/O-взаимодействия.
Ключевая проблема - блокирующий вызов нарушает работу узла.
Неблокирующие методы работы с сокетами подходят, но схема ожидания их результата должна быть реализована через средства предоставляемой библиотеки, чтобы избежать лишнего опроса сокетов и пробуждения файберов.
Иными словами, транспортировку данных и их ожидание нужно делать через обертки над примитивами Tarantool и, в частности, CoIO.
Это накладывает мораторий на использование большинства готовых библиотек, например HTTP-клиента “reqwest” и HTTP-сервера “axum” из экосистемы Rust.

Одним из обходных путей является поднятие сторонней среды исполнения - еще одного набора потоков, и делегирование I/O работы на них.
Возникает проблема синхронизации двух сред исполнения - TX-потока Tarantool и сторонней среды.
Это зачастую приемлемое решение, и нередко используется в реальности, особенно когда необходимо использовать готовую библиотеку, предоставляющую обертку над HTTP-API некоторого сервиса.
В таких случаях используют библиотеку “tros”, реализующую удобный интерфейс для взаимодействия со сторонней средой исполнения.
У такого решения есть и недостатки: необходима синхронизация между потоками, передача данных между ними.
При интенсивности HTTP-трафика это приводит к нежелательному увеличению задержки обработки запроса.

Самым оптимальным по производительности выбором в итоге остается построение собственного фреймворка, используя предоставляемые Tarantool примитивы для неблокирующего I/O.
Так и построено существующее решение: реализован фреймворк HTTP на Lua, интегрирующийся с CoIO - системой неблокирующего I/O для Tarantool.
Поверх него уже для простоты реализации был построен Rust-фреймворк “shors”, помимо прочего предоставляющий удобное API и автоматическую генерацию OpenAPI-схемы.
В рамках этого перехода и происходит потеря ценного времени - Lua-фреймворк корректно интегрируются с CoIO, но полученные данные еще необходимо передать в среду исполнения Rust для дальнейшей обработки.

На рисунке 1.2 показаны слои работы текущего решения в упрощенном виде.
Вертикальное расположение сверху-вниз совпадает с уровнями абстракции.
На самом верху самый высший слой абстракции - пользовательская логика: эндпоинты, функции для их обработки, пользовательские типы десериализации.
Пользовательская логика реализуется с использованием фреймворка shors.
Shors в свою очередь превращает пользовательские обработчики в Lua-функции с помощью библиотеки “tlua”, регистрирует их в глобальном HTTP-сервере, установленном в среде исполнения Lua.
HTTP-сервер в свою очередь использует примитивы Tarantool - библиотеку CoIO, интегрирующую с libeio.

\begin{figure}[!h]
	\caption*{Рисунок 1.2 - Схема архитектуры текущего решения}\label{fig2}
	\centering
	\includegraphics{existing_architecture}
\end{figure}


Преимуществом такого решения с точки зрения команды Picodata является простота реализации и поддержки - shors является небольшой библиотекой, не требующей особого ухода.
При появлении новых требований - например, интеграции генератора OpenAPI-схем, достаточно небольших включений.

Недостатком является лишний слой во взаимодействии с примитивами Tarantool - по сути для реализации высокоуровневого фреймворка shors используется другой высокоуровневый фреймворк - Lua HTTP-сервер.
В результате страдает производительность.

\section{Анализ акторных групп}\label{sec:analyze_actors}

Для формирования концепции будущего решения и его дальнейшей реализации критически необходимо изучить акторные группы существующего решения и сформировать их схематическое представление - диаграмму прецедентов.
Без этого можно упустить некоторые важные потребности пользователей, не включив их в архитектуру продукта.

Компания Picodata имеет ряд продуктов, которые используют Tarantool и фреймворк cartridge, и с очень малой вероятностью будут переделаны на полноценное использование СУБД Picodata.
Такие клиенты используют текущее решение - фреймворк shors, для реализации HTTP-интерфейса.
Компания Picodata не видит ценности в улучшении производительности HTTP-API для этих продуктов, поскольку в них нужные цели по SLA достигнуты.
Соответственно, эта акторная группа исключается из рассмотрения - клиенты будут продолжать использовать фреймворк “shors”.

Активной акторной группой являются клиенты, полноценно использующие СУБД Picodata - авторы плагинов.
На данный момент они используют “shors” для реализации HTTP-API: на новом фреймворке они хотят  аналогичную функциональность: возможность создания API-эндпоинтов с пользовательской логикой, в будущем - возможность генерации OpenAPI-схемы.

Схожей и релевантной акторной группой являются разработчики СУБД Picodata: улучшенное решение необходимо для использования внутри самой СУБД Picodata.
Сейчас СУБД Picodata представляет HTTP-API для административных целей, включая эндпоинт для сбора метрик.

В результате формируется диаграмма прецедентов, показанная на рисунке 1.3.
Наследование акторной группы пользователя остальных групп показывает, что для конечного фреймворка пользователи равнозначны.
Однако наличие двух акторных групп - важный аспект, поскольку демонстрирует присутствие нескольких потоков интересующих дополнений.

\begin{figure}[!h]
	\caption*{Рисунок 1.3 - Диаграмма прецедентов решения}\label{fig3}
	\centering
	\includegraphics{actor_groups}
\end{figure}

\section{Формирование функциональных и нефункциональных требований}\label{sec:requirements}

В результате уже приведенного анализа и коммуникации с разработчиками СУБД Picodata можно выделить следующие нефункциональные требования:

\begin{enumerate}[label=\arabic*.]
	\item фреймворк должен быть в легком доступе для всех акторов - в идеале, будучи Rust-библиотекой, он должен быть представлен в публичном реестре “crates.io”;
	\item фреймворк должен предоставлять качественные абстракции: детали реализации и особенности транспорта Tarantool CoIO должны быть скрыты;
	\item фреймворк должен быть открытым ПО: HTTP-сервер - обширная тема, и возможность легкого содействия поможет привлечь сторонних разработчиков;
	\item фреймворк должен просто интегрироваться с библиотекой SDK плагинов: например, посредством реэкспорта.
\end{enumerate}

В результате изучения текущих решений с технической точки зрения и опроса акторов были выделены следующие функциональные требования:

\begin{enumerate}[label=\arabic*.]
	\item фреймворк должен предоставлять функционал пользовательской маршрутизации и обработки запросов;
	\item должна быть реализована поддержка основных HTTP-методов (GET, POST, PUT, DELETE и пр.);
	\item должна быть возможность создать эндпоинты с возможностью использования параметров запроса, группировки по тэгам;
	\item фреймворк должен просто интегрироваться с библиотекой SDK плагинов: например, посредством реэкспорта;
	\item необходима возможность реализовать middleware для предварительной и последующей обработки запросов: включая пользовательские и встроенные - для, например, логирования и обработки ошибок;
	\item фреймворк должен интегрироваться с I/O-системой Tarantool. Ожидание данных и ответ на них должны быть неблокирующими и не приводить к остановке транзакционного потока.
\end{enumerate}

\section{Формирование архитектуры будущего решения}\label{sec:new_architecture}

Далее необходимо сформировать архитектуру для дальнейшей реализации продукта.
Концепция использования транспорта Tarantool - систему CoIO, не может быть опущена, транспорт нужно использовать для максимальной производительности.
В Rust-экосистеме СУБД Picodata уже присутствует проект, интегрирующийся с транспортом и выполняющий задачу, связанную с HTTP-трафиком - библиотека “fibreq”\nameref{lit:fibreq}, выполняющая роль быстрого HTTP-клиента.
Его архитектура показана на рисунке 1.4.

\begin{figure}[!h]
	\caption*{Рисунок 1.4 - Архитектура HTTP-клиента fibreq}\label{fig4}
	\centering
	\includegraphics{fibreq_architecture}
\end{figure}

Внутренне он интегрируется с реализацией асинхронного программирования Rust библиотеки “tarantool-module”\nameref{lit:tt_mod}, которая в свою очередь использует примитивы CoIO для неблокирующих операций.
Однако транспорт - только часть необходимого функционала, ведь после получения данных с сокета их необходимо эффективно обработать: изначально это просто сырые байты.
Нужно еще высокопроизводительное SDK, которое обеспечивает примитивы и алгоритмы для экстракта заголовков, тела и прочих частей запроса.
Для fibreq таким фреймворком был по историческим причинам выбран async-h1: поскольку в его случае не делается предположение о запущенной асинхронной среде исполнения.
Компания Picodata попробовала интегрировать транспортные библиотеки, использующие самый популярный асинхронный рантайм Tokio, однако они предполагают его многопоточный запуск, что не удовлетворяет условиям транзакционного потока.
Библиотека async-h1 более низкоуровневая и потому абстрагируется от транспортной системы и асинхронного рантайма.
Однако есть и недостаток: async-h1 редко обновляется, поддержка минимальна, а также присутствует только версия протокола HTTP/1.1.

В Rust все высокоуровневые HTTP-фреймворки вроде axum, actix-web, интегрируются с hyper\nameref{lit:hyper} - эффективным SDK для работы с HTTP-трафиком.
Одной из важных особенностей hyper является качественное разделение на слои - можно пользоваться как достаточно высокоуровневым фреймворком hyper, который интегрируется с асинхронным рантаймом, так и внутренними библиотеками, вроде h1, h2, h3.
По сути axum, actix-web, и подавляющее большинство остальных HTTP-фреймворков в Rust-экосистеме - удобные надстройки над hyper.

Для реализации целевого решения предлагается использовать именно hyper - относительно недавно фреймворк получил возможность абстрагироваться от используемого асинхронного рантайма, разработчики стремятся минимизировать зависимости от используемых библиотек.
Это значит, что нет принципиальных препятствий в том, чтобы принести собственный асинхронный рантайм - для этого существует трейт Executor.
Поддержка разных транспортов тоже скрыта за абстрактными интерфейсами - для этого существуют трейты Read и Write, представляющие простые аналоги для синхронных вариантов с теми же именами из стандартной библиотеки Rust.

В результате получается архитектура, указанная на рисунке 1.5.
Она похожа на архитектуру HTTP-клиента fibreq, но использует hyper в качестве реализации основной функциональности HTTP-сервера.
Асинхронный рантайм библиотеки tarantool-module реализует интерфейс Executor, а абстракция над CoIO TcpStream - AsyncRead и AsyncWrite.
Также отражен компонент, еще отсутствующий в SDK tarantool-module - неблокирующий TcpListener, аналогичный по функциональности TcpListener из стандартной библиотеки.
Он необходим для инициализации нового подключения и создания для него отдельного сокета и дальнейшего его использования через существующую абстракцию TcpStream.

\begin{figure}[!h]
	\caption*{Рисунок 1.5 - Архитектура нового решения Weaver}\label{fig5}
	\centering
	\includegraphics{weaver_architecture}
\end{figure}

Преимуществом такого подхода является производительность, поддержка со стороны экосистемы - обновления hyper, повышающие стабильность, будут в легком доступе.
Нет необходимости изобретать собственный парсер версий HTTP-протокола - все, что доступно в hyper, будет доступно в конечном веб-фреймворке.
Задача сводится к созданию эргономичного API и аккуратной интеграции с транспортом и асинхронным рантаймом Tarantool и библиотеки tarantool-module.

\leftalignedtrue
\chapter{Реализация}
\leftalignedfalse

\section{Реализация TcpListener}\label{sec:impl_tcp_listener}

В SDK tarantool-module отсутствовала реализация необходимого серверного компонента - TcpListener.
В стандартной библиотеке Rust есть блокирующая реализация TcpListener, асинхронный фреймворк tokio также представляет свою неблокирующую реализацию.
По аналогии с существующими вариантами был создан и неблокирующий TcpListener для асинхронного рантайма tarantool-module.
Ключевой компонент TcpListener - метод приема новых подключений accept, код которого показан в листинге А.1.
Для начала вызывается системный вызов accept4, позволяющий сразу задать нужные параметры для создаваемых сокетов.
Устанавливаются флаги CLOEXEC и NONBLOCK для автоматического закрытия и неблокирующего режима соответственно.
Далее обрабатывается результат системного вызова - если на сокете еще нет подключений - вынужден заблокироваться, то необходимо их дождаться через CoIO.
Поэтому асинхронному контексту выставляется ожидание событий чтения на главном сокете.

Теперь реализуется использование этой функции в главном цикле веб-сервера, как показано в листинге А.2.
Сначала вызывается метод "bind" для получения главного сокета и установки его на нужном порту, а затем бесконечно ожидается принятие нового подключения через "accept".

\section{Реализация тестового приложения}\label{sec:impl_test_app}

Было реализовано тестовое приложения - модуль для СУБД Tarantool, использующий библиотеку weaver.
Его бизнес-логика показана в листинге А.3 - он определяет специальный эндпоинт "/echo".
Этот эндпоинт возвращает тело запроса без изменений, таким образом проверяется, что сервер может корректно прочитать тело и отправить ответ.

\section{Написание тестов первичной реализации}\label{sec:impl_tests}

Для начала был написан тест первичной реализации на языке Python, фреймворке pytest, код которого показан в листинге А.4.
Технологический стек для интеграционного тестирования выбран неслучайно: pytest - мировой стандарт тестирования, интеграционные тесты самой Picodata также написаны на нем, и самое главное - в его рамках действительно просто тестировать HTTP API, что и будет основной нагрузкой.
Тест отправляет запросы на специальный эндпоинт "/echo".

%% Макрос для заключения. Совместим со старым стилевиком.
\startconclusionpage

В ходе практики планируемая цель - детальный анализ проблемы HTTP-сервера в СУБД Tarantool/Picodata и начальная реализация нового, была достигнута.
Была изучена проблема, исследование которой привело к созданию фреймворка weaver.
Были изучены акторные группы, в результате чего была построена диаграмма прецедентов.
Так же были изучены существующие аналоги и современные подходы для реализации неблокирующего HTTP-сервера.
Выяснилось, что создания собственного веб-фреймворка было не избежать - конкурентные решения имеют ценные детали, но не удовлетворяют всем требованиям к продукту.
Еще одной важной решенной задачей стало формирование функциональных и нефункциональных требований к системе: полученные списки в дальнейшем будут использованы для оценки финальной версии.

Была сформирована архитектура будущего решения и его первичная реализация. Был написан тест, демонстрирующий корректную работоспособность неблокирующего веб-фреймворка.

\startsourcespage

\begin{enumerate}[label=\arabic*.]
	\item \customlabel{lit:highload}{[1]} \detokenize{Высоконагруженные приложения: программирование, поддержка, масштабирование / Мартин Клеппман; [перевели с англ. И. Пальти, А. Тумаркин]. – Санкт-Петербург: Питер, 2022. – 637 с.: ил. – (Бестселлеры O’Reilly). – ISBN 978-5-4461-0512-0;}
	\item \customlabel{lit:tt_doc}{[2]} \detokenize{Документация Tarantool [Электронный ресурс]. – 2024. – URL: https://www.tarantool.io/en/doc/2.11/ (дата обращения: 01.04.2024);}
	\item \customlabel{lit:picodata_doc}{[3]} \detokenize{Документация Picodata [Электронный ресурс]. – 2024. – URL: https://docs.picodata.io/picodata/stable/ (дата обращения: 01.04.2024);}
	\item \customlabel{lit:tt_code}{[4]} \detokenize{Исходный код Tarantool [Электронный ресурс]. – 2024. – URL: https://github.com/tarantool/tarantool (дата обращения: 01.04.2024);}
	\item \customlabel{lit:tt_mod}{[5]} \detokenize{Исходный код Tarantool Module [Электронный ресурс] // URL: https://github.com/picodata/tarantool-module (дата обращения: 01.04.2025);}
	\item \customlabel{lit:hyper}{[6]} \detokenize{Исходный код фреймворка Hyper [Электронный ресурс] // URL: https://github.com/hyperium/hyper (дата обращения: 01.04.2025);}
	\item \customlabel{lit:tt_http}{[7]} \detokenize{Исходный код HTTP-сервера Tarantool [Электронный ресурс] // URL: https://github.com/tarantool/http (дата обращения: 01.04.2025);}
	\item \customlabel{lit:shors}{[8]} \detokenize{Исходный код фреймворка shors [Электронный ресурс] // URL: https://git.picodata.io/picodata/mod/http-router (дата обращения: 01.04.2025);}
	\item \customlabel{lit:libev}{[9]} \detokenize{Домашняя страница проекта Libev [Электронный ресурс] // URL: http://software.schmorp.de/pkg/libev.html (дата обращения: 01.04.2025);}
	\item \customlabel{lit:fibreq}{[10]} \detokenize{Документация fibreq [Электронный ресурс] // URL: https://docs.rs/fibreq/latest/fibreq (дата обращения: 01.04.2025).}
\end{enumerate}

%% После этой команды chapter будет генерировать приложения, нумерованные русскими буквами.
%% \startappendices из старого стилевика будет делать то же самое
\appendix

\chapter{Листинги реализации}\label{sec:app:1}

\begin{lstlisting}[float=!h,caption={Реализация ключевого метода accept},label={lst1}]
pub async fn accept(&self) -> Result<TcpStream, Error> {
    let raw_fd = self.connections_stream.fd()?;
    let f = future::poll_fn(|cx| {
        if let Err(error) = check_socket_error(&raw_fd) {
            // SAFETY: this fd is still valid and was not closed.
            unsafe { AutoCloseFd::from_raw_fd(raw_fd) };
            return Poll::Ready(Err(Error::Accept { error }));
        }

        let mut dummy =
            std::mem::MaybeUninit::<libc::sockaddr>::uninit();
        let mut dummy_size = std::mem::size_of_val(&dummy) as _;

        let accept_result = cvt(unsafe {
            libc::accept4(
                raw_fd,
                dummy.as_mut_ptr(),
                &mut dummy_size,
                libc::SOCK_CLOEXEC | libc::SOCK_NONBLOCK,
            )
        });

        match accept_result {
            Ok(raw_fd) => return Poll::Ready(Ok(raw_fd.into())),
            Err(error) => {
                if error.kind() == io::ErrorKind::WouldBlock {
                    unsafe {
                        ContextExt::set_coio_wait(
                            cx,
                            raw_fd,
                            ffi::CoIOFlags::READ
                        );
                    }
                    return Poll::Pending;
                }
                return Poll::Ready(Err(Error::Accept { error }));
            }
        };
    });
    f.await
}
\end{lstlisting}

\begin{lstlisting}[float=!h,caption={Главный цикл веб-сервера},label={lst2}]
let listener = TcpListener::bind(&bind.host, bind.port).map_err(|err| {
    Error::InitFailed(format!("failed to bind to needed address: {err}"))
})?;
info!(
    "Server bind to address {}:{} successfully",
    bind.host, bind.port
);

loop {
    let stream = listener
        .accept()
        .await
        .map_err(|err| Error::ConnectionError(err.to_string()))?;

    debug!("Server accepted new connection");
}
\end{lstlisting}

\begin{lstlisting}[float=!h,caption={Бизнес-логика тестового приложения},label={lst3}]
struct EchoEndpoint;

#[async_trait::async_trait]
impl RequestHandler for EchoEndpoint {
    type Error = anyhow::Error;

    async fn handle_async(
        &self,
        request: Request<Incoming>,
    ) -> Result<Response<Body>, Self::Error> {
        let content = request.collect().await?.to_bytes();
        let body = Body::from(String::from_utf8(content.to_vec())?);
        Ok(Response::new(body))
    }
}
\end{lstlisting}

\begin{lstlisting}[float=!h,caption={Тест первичной реализации},label={lst4},language=python]
import httpx
import pytest

@pytest.mark.asyncio
async def test_echo_endpoint(test_app):
    client = httpx.AsyncClient(base_url=test_app)

    response = await client.get("/echo")
    assert response.status_code == 200, f"invalid response: {response}"
    assert response.text == ""

    json_data = {"hello": "world"}
    response = await client.post("/echo", json=json_data)
    assert response.status_code == 200, f"invalid response: {response}"
    assert response.json() == json_data
\end{lstlisting}


\end{document}
